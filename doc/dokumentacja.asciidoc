Technika mikroprocesorowa 2
===========================
Marcin Łoś, Michał Torba 

:numbered:

Założenia projektu
------------------

Celem projektu było zaprojektowanie oraz implementacja w języku C biblioteki umożliwiającej operacje 
na liczbach rzeczywistych bez wykorzystania wsparcia sprzętowego. Powinna udostępniać ona funkcje 
realizujące podstawowe działania arytmetyczne (dodawanie, odejmowanie, mnożenie, dzielenie),
wybrane funkcje elementarne (pierwiastek kwadratowy, logarytm, funkcję wykładniczą, funkcje
trygonometryczne - sinus, cosinus, tangens, cotangens), oraz konwersje pomiędzy liczbami całkowitymi,
a zaimplementowanym formatem rzeczywistym.


Wstępny plan realizacji
-----------------------

Przed rozpoczęciem implementacji omówiliśmy główne aspekty problemu i opracowaliśmy spójną wizję
dalszych prac.

Format
~~~~~~
Najniższą warstwę problemu stanowi wybór formatu reprezentacji liczb rzeczywistych. Mieliśmy kilka możliwości do wyboru:

* *Floating poing* (w szczególności IEEE 754)
* *Fixed point* (Stały przecinek)
* *BCD* (Binary Coded Decimal)

Kolejny paragraf stanowi krótki opis poszczególnych formatów z powyższej listy.

Floating point
^^^^^^^^^^^^^^

Reprezentacje typu _floating-point_ polegają na rozbiciu liczby rzeczywistej na znak, wykładnik 
(cechę) i mantysę, powiązane następującą równością:

+x = (-1)^s^ m b^t^+

Standard IEEE 754 opisuje najpopularniejszą obecnie rodzina reprezentacji liczb
zmiennoprzecinkowych. Wersja z roku 2008 opisuje formaty 16, 32, 64, 80 i 128-bitowe. Poza wartościami reprezentującymi poprawne liczby rzeczywiste, standard opisuje reprezentacje obydwu
nieskończoności, oraz błędnych wartości, tzw. 'NaN' ('Not a Number'). 

Za wyborem tej reprezentacji przemawia fakt, iż na dzień dzisiejszy posiada ona dominację
wśród wszystkich reprezentacji liczb rzeczywistych. Co za tym idzie,

* wykorzystujemy sprawdzony pomysł
* łatwo znaleść kompleksowe opisy i przykładowe implementacje
* łatwo przeprowadzać testy - niemal każdy komputer posiada sprzętową implementację IEEE 754,
czego nie sposób powiedzieć o pozostałych formatach



Fixed point
^^^^^^^^^^^
Również i w tym formacie korzystamy z rozbicia liczby na znak, wykładnik i mantysę, jednakowoż
nie przechowujemy bezpośrednio cechy - posiada ona znaną, z góry określoną wartość. W ten sposób
dostajemy format, w którym wagi poszczególnych bitów są stałe, zależne jedynie od określonej 
wcześniej wartości cechy.

Rozwiązanie zdaje się być stosunkowo proste pod względem implementacyjnym. Z punktu widzenia 
użytownika posiada jednakowoż znaczące wady:

* _Niewielki zakres reprezentowalnych wartości lub niewielka precyzja_ - innymi słowy, jak dobrać
wykładnik? Mamy do dyspozycji stałą ilość liczb do reprezentowania liczb rzeczywistych rozłożonych
równomiernie po pewnym przedziale, zatem +(długość przedziału) * (dokładność) = const+. Dla mocno 
ujemnych wartości wykładnika reprezentacja będzie stosunkowo dokładna, natomiast  przedział
reprezentowalnych wartości będzie zbyt mały do pewnych zastosowań, zaś dla większych wartości
wykładnika rozmiar przedziału wzrośnie, natomiast dokładność zmaleje. Nie sposób dobrać wartości
zaspakajające potrzeby wszystkich problemów obliczeniowych.
* _Słabe wykorzystanie zbioru reprezentowalnych wartośc_ - dokładność bezwzględna reprezentacji jest
identyczna na całym przedziale, a co za tym idzie dokładność względna w okolicach zera jest 
znacznie mniejsza, niż w pobliżu końców przedziału reprezentowalnych wartości. Zazwyczaj gdy
obliczenie operuje na liczbach o większej wartości bezwzględnej, godzimy się na większy błąd
bezwzględny z uwagi na fakt, iż błąd względny pozostaje podobny do tego dla małych liczb. Przy 
reprezentacji fixed point nie bierzemy tego pod uwagę.


BCD
^^^

Binary Coded Decimal to w ogólności kodowanie liczb w postaci dziesiętnej, wykorzystujące na każdą
cyfrę bajt (wesja podstawowa) lub 4 bity (nibble) (wersja spakowana). W zależności od sposobu
interpretacji takiego ciągu cyfr, na BCD zbudować można reprezentację stało- lub zmiennoprzecinkową.
Nie jest to reprezentacja na dzień dzisiejszy szeroko wykorzystywana sprzętowo.

Z punktu widzenia implementacji niewątpliwą zaletą BCD jest prostota interpretacji bitów poprawnie
zakodowanych liczb. Niestety trudno rozszerzyć tę listę o cokolwiek innego. Poprawność liczby
zakodowanej w formacie BCD jest stosunkowo kosztowna do sprawdzenia (wartość każdego 4-bitowego
kawałka musi być nie większa niż 9). Wykonywanie podstawowych operacji, takich jak dodawanie
czy odejmowanie, również wymaga ręcznej implementacji. Niektóre architektury (np. x86) udostępniają
instrukcje operujące na danych w formacie BCD (jak choćby +DAA+/+DAS+ we wspomnianym x86), jednakowoż
nie są one dostępne z poziomu języka implementacji, co czyni ich wykorzystanie co najmniej
kłopotliwym i niepożądanym. 

Ostateczny rezultat
^^^^^^^^^^^^^^^^^^^ 

Ostatecznie zdecydowaliśmy się na wykorzystanie formatu IEEE 754, z uwagi na powszechność jego 
użycia, i idącą za tym łatwość testowania.


Algorytmy ewaluacji funkcji
~~~~~~~~~~~~~~~~~~~~~~~~~~~


Wszystkie zaimplementowane algorytmy funkcji opierają się na metodzie zastosowanej w pracy 'An Accurate Elementary Mathematical Library for the IEEE Floating Point Standard' będącej naszą wyrocznią pod tym względem. W poszukiwaniu takiego właśnie opisu natknęliśmy się na wiele innych prac, większość z nich mówiła jednak o optymalizacji poszczególnych metod wykorzystując możliwości platform docelowych (co nie szło by w parze z ideą ogólności), lub z wykorzystaniem trudnych w implementacji i nietrywialnych w idei przejść, które wykraczałyby poza skalę projektu.


Implementacja
-------------

Prace nad implementacją produktu końcowego podzielić można dość wyraźnie na 2 etapy: realizacja
podstawowych operacji arytmetycznych i funkcji pomocniczych niskiego poziomu, zajmujących się
dostarczeniem narzędzi niezbędnych do dostarczenia bardziej zaawansowanej funkcjonalności,
oraz implementacja samych funkcji matematycznych. Etapy te okazały się w gruncie rzeczy niemal
całkowicie niezależne, gdyż jakkolwiek algorytmy ewaluacji funkcji wykorzystują w kluczowy sposób
środowisko dostarczane przez pierwszą, niższą warstwę, to z powodzeniem zastąpić można ją na czas
implementacji klasyczną arytmetyką zmiennoprzecinkową, realizowaną sprzętowo przez procesor.
Przy założeniu, że nie będzie wyraźnych obserwowalnych różnic w funkcjonowaniu tych dwóch realizacji
tego samego konceptu, przejście od użycia jednej do drugiej nie powinno wymagać ingerencji w kod
ponad zwykła podmianę operatorów na wywołania funkcji realizujących odpowiadające im operacje.
Praktyka potwierdziła to przypuszczenie, i integracja dwóch realizowanych niezależnie warstw 
przebiegła bez poważniejszych problemów.

Wykorzystane narzędzia
~~~~~~~~~~~~~~~~~~~~~~
Kod projektu pisany był w środowisku Eclipse z wtyczką CDT. Projekt kompilowany był przy użyciu
kompilatora GCC 4.7.2. Do zarządzania procesem budowania wykorzystaliśmy GNU Autotools (autoconf,
automake, libtool). Do testów jednostkowych wykorzystaliśmy C++ i bibliotekę CxxTest. Interaktywny
shell zbudowany został przy użyciu standardowych do tego typu zastosowań narzędzi - Lex/Yacc + GNU
Readline. Dokumentacja API wygenerowana została z komentarzy w kodzie źródłowym przy użyciu systemu
Doxygen.



Implementacja warstwy podstawowych operacji
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Jako format reprezentacji liczb rzeczywistych wybrany został 64-bitowy wariant opisany w IEEE 754.
W większości implementacji C odpowiada on popularnemu typowi +double+. 

.Szczegół implementacyjny
[NOTE]
===========================================================
Powszechnie wiadomo, że herkulesową niemal pracę stanowi pisanie w pełni przenośnego
niskopoziomowego oprogramowania w C/C$$++$$, z uwagi na swobodę, jaką standardy pozostawiają
implementatorom. O ile nam wiadomo, nie sposób uzyskać we w pełni przenośiny sposób typu
całkowitego o wielkości 64 bitów. Najbliżej realizacji tego zadania zdaje się być +uint64_t+
z nagłówka +<stdint.h>+, jednak ściśle rzecz biorąc, jego istnienie zależy od dobrej woli
implementatora. Obejścia tego problemu przy użyciu np. tablicy +char+-ów, czy też struktury 
ją zawierającej w celu zachowania pełnej formalnej jest możliwa, wymaga jednak ostrożnego
lawirowania między subtelnymi nieraz przypadkami Undefined Behaviour, czychającymi na każdym
kroku na nieświadomego wędrowca. Stąd uwaga ogólna odnośnie całego kodu: nie dołożyliśmy, ze
względów praktycznych, wszelkich starań, by uniknąć dobrze zrozumianych i powszechnie
występujących przypadków UB (jak choćby rzutowanie przez unię, bądź naruszanie w inny
sposób reguł aliasowania).
===========================================================

Sposób reprezentacji
^^^^^^^^^^^^^^^^^^^^

Ażeby zaimplementować operacje arytmetyczne oraz funkcje pomocnicze pracujące na liczbach
zmiennoprzecinkowych podwójnej precyzji w formacie IEEE 754, konieczne jest dokładne poznanie
jego anatomii. Liczba taka składa się z 8 bajtów, podzielonych logicznie na 3 sekcje:

.IEEE 754 (podwójna precyzja)
[options="header",cols="^2,^3,^10",width="50%"]
|======================================
|1 bit      |11 bitów    |52 bity 
|znak (+s+) |cecha (+e+) |mantysa (+m+)
|======================================

W najprostszym przypadku bity te opisują liczbę daną poprzez 

+x=(-1)^s^2^e-e~0~^*1.m+

Dokładna interpretacja wartości tych pól zależy w pewnej mierze od rodzaju liczby, z jaką mamy
do czynienia, i opisana jest w kolejnych podpunktach.

Rodzaje liczb
^^^^^^^^^^^^^

Standard wyróżnia  rodzaje liczb reprezentowalnych przez wartości 8-bajtowe. Zbiory liczb
8-bajtowych im odpowiadających stanowią podział zbioru wszystkich wartości, tzn. są rozłączne,
a ich unia to cały ten zbiór.

* *Liczby znormalizowane*
* *Liczby zdenormalizowane*
* *Zero*
* *Nieskończoność*
* *NaN*

Liczby znormalizowane
+++++++++++++++++++++

Ich wyróżnik stanowi wykładnik w zakresie 1-2046. Ten typ wartości służy do reprezentowania
zwyczajnych liczb rzeczywistuch z zakresu [2.225 x 10^-308^, 1.798 x 10^308^]. Trójka
+(s, e, m)+ to reprezentacja liczby +(-1)^s^ * 2^e-1024^ * 1.m+, gdzie zapis +1.m+ dla
+m = m~1~ m~2~ $$...$$ m~52~+ oznacza 
+1 + m~1~2^-1^ $$+$$ m~2~2^-2^ $$ + ... + $$ m~52~2^-52^+

Liczby zdenormalizowane
+++++++++++++++++++++++

Jeśli liczba posiada wyzerowane pole wykładnika oraz niezerową mantysę, jest interpretowana jako
liczba zdenormalizowana. Liczby takie reprezentują wielkości o wartości bezwzględnej mniejszej, 
niż pozwala na to konstrukcja liczby znormalizowanej. Są one interpretowane w specjalny sposób,
różniący się nieco od przypadku znormalizowanego. Trójka +(s, 0, m)+ to reprezentacja liczby
+(-1)^s^ * 2^-1023^ * 0.m+ (a więc wykładnik to +e-1023+ zamiast +e-1024+, a mantysa nie ma
niejawnej jedynki). Te zmiany interpretacji pozwalają uzyskać liczby równomiernie rozłożone na
przedziale +($$-$$a, $$+$$a)+, gdzie +a+ to najmniejsza dodatnia liczba znormalizowana.

Pomimo prostoty koncepcji, poprawna obsługa liczb zdenormalizowanych potrafi sprawiać czasem
problemy w nieoczekiwanych miejscach, z uwagi na specjalne reguły interpretacji. Najczęściej 
jest to jednak po prostu przykry obowiązek, a nie poważna trudność.

Zero
++++

Zera reprezentowane są jako liczby z zerowym polem wykładnika oraz zerową mantysą. Pole znaku
jest dowolne, co, jak łatwo zauważyć, prowadzi do istnienia dwóch różnych pod względem bitowym
reprezentacji tej liczby. Rozróżniamy zatem zero dodatnie i zero ujemne. Podczas wszelkich
porównań znak zera jest ignorowany, jest natomiast istotny przy niektórych operacjach 
arytmetycznych, np. +1/($$+0$$) = $$+$$inf+, natomiast +1/(-0) = -inf+.

Nieskończoność
++++++++++++++

Nieskończoności reprezentowane są w IEEE 754 jako liczby z polem wykładnika o wartości 2047 
(największy możliwy, tj. 11 bitów ustawionych na 1, +0x7ff+) oraz zerową mantysą. Bit znaku
zwyczajnie określa znak nieskończoności. Operacje arytmetyczne z udzialem wartości nieskończonych
są zdefiniowane następująco (+@+, +#+ oznacza plus lub minus):

* +$$@inf + a = @inf$$+ dla +a != -@inf+
* +$$@inf - a = @inf$$+ dla +a != @inf+
* +$$@inf - @inf = NaN$$+
* +$$@inf * a = sgn(a) * @inf$$+ dla +a != 0+
* +$$@inf * 0 = NaN$$+, niezależnie od znaku +0+
* +$$@inf / #inf = NaN$$+
* +$$@inf / a = #inf$$+ dla skończonych +a+, gdzie +# = xor(sgn(@inf), sgn(a))+
* +$$a / @inf = 0$$+ dla +a != #inf+, przy czym znak zera zależy w sposób naturalny od znaków +a+
oraz +@+

NaN
+++

Do reprezentowania wartości będących wynikiem niepoprawnej operacji wykorzystywany jest specjalny
rodzaj wartości - +NaN+ (+Not a Number+). Jest ona reprezentowana poprzez liczbę z polem wykładnika
o wartości 2047 (jak nieskończoności), i niezerową mantysą. Wszelkie operacje arytmetyczne z udziałem
+NaN+ dają rezultat +NaN+. Zachowuje się on również osobliwie przy porównaniach - +NaN != NaN+.

Implementacja operacji arytmetycznych
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Założenia projektowe
++++++++++++++++++++

Pierwotnie planowaliśmy realizację podstawowych operacji w pełni zgodną z IEEE 754. Zadanie takie
wymaga, poza zwyczajnym obliczeniem wartości, poprawnego jej zaokrąglenia, tj. przedstawienia 
dokładnie obliczonego wyniku w stosowanym formacie. Jest to konieczne z uwagi na fakt, iż zbiór
liczb reprezentowalnych w formacie podwójnej precyzji nie jest zamknięty ze względu na operacje 
arytmetyczne. Standard opisuje kilka trybów zaokrąglania, przy czym najpowszechniej stosowany to 
zaokrąglanie do najbliższej wartości reprezentowalnej rozwiązującej konflikty (sytuacje, w których
wartość dokładna leży dokładnie w połowie pomiędzy dwoma reprezentowalnymi wartościami) na korzyść
tej liczby, która posiada parzystą ostatnią cyfrę mantysy (+roundTiesToEven+). Rozwiązanie takie
jest symetryczne względem znaku, dzięki czemu unikamy przesuniecia średniej względem zera, które 
występuje w niektórych innych trybach zaokrąglania.

Realizacja
++++++++++

Niezbędny do jakichkolwiek innych operacji jest sposób przechodzenia między wartościami w postaci
zakodowanej (z polami upakowanymi na 64 bitach zgodnie z uprzednio przedstawionym diagramem),
a w postaci krotki trójelementowej, zrealizowanej jako struktura z trzema polami. Jedynym problemem
na tym etapie jest specjalne traktowanie liczb zdenormalizowanych, niemniej dopracowanie szczegółów
jest względnie proste, więc nie będą tutaj przytaczane. Konwersje te dostarczają pierwszej, 
najbardziej podstawowej warstwy abstrakcji nad surową pamięcią.

Kolejne paragrafy opisują sposób zrealizowania kolejnych operacji arytmetycznych.

.Mnożenie
Najłatwiejszym działaniem okazało się mnożenie, z uwagi na prostotę koncepcji tej operacji w
przyjętym formacie. Są oczywiście dodatkowe komplikacje i trudności implementacyjne, ale ogólna idea
operacji mnożenia wyraża się w następującej równości. Dla +x = (-1)^s~x~^ *
2^e~x~^ * M~x~+, +y = (-1)^s~y~^ * 2^e~y~^ * M~y~+ mamy

+x * y = (-1)^s~x~+s~y~^ * 2^e~x~+e~y~^ * M~x~ * M~y~+

Poza wykryciem i obsługą przypadków specjalnych, opisanych w jednej z poprzednich sekcji o rodzajach
liczb, jedyny problem stanowi obliczenie +M~x~ * M~y~+. Są to w ogólności wielkości 53-bitowe 
(52 bity mantysy i niejawna jedynka dla liczb znormalizowanych), zatem nie sposób dokonać dokładnego
ich mnożenia używając wyłącznie arytmetyki 64-bitowej. Przewidując podobne problemy przy pozostałych
operacjach, zaimplementowaliśmy zestaw operacji na 128-bitowych liczbach całkowitych. Jest to więcej,
niż jest potrzebne do dokładnego obliczania tych wartości, jednak przy implementacji software'owej
optymalizowanie operacji pod tym kątem mija się z celem.

Wynik mnożenia dwóch wielkości 53-bitowych to w przypadku ogólnym liczba +(2*53 - 1)+-bitowa, zatem
wynik należy przesunąć o 52 bity w prawo. W przypadku, gdy obydwie mantysy należały do liczb
znormalizowanych, na tym można poprzestać; bit 53 jest z całą pewnością ustawiony na 1, zatem
mantysa wynikowa należy do liczby znormalizowanej. Sytuacja komplikuje się, gdy jedna z mnożonych
liczb jest zdenormalizowana. Wówczas może zdarzyć się, że otrzymamy wynik z 53-cim bitem zerowym.
Podówczas dokonać należy *renormalizacji* - procesu przywrócenia liczbie własności normalizacji
poprzez odpowiednie przesunięcie mantysy - "dosunięcie" najwyższego niezerowego bitu na pozycję
53 - oraz poprawienie wykładnika, aby zachować wartość liczby po zmianie mantysy.

Ostatecznie więc algorytm mnożenia w pseudokodzie wygląda następująco:

.Mnożenie (pseudokod)
----
Rozpakuj wartości do struktur
Sprawdź przypadki specjalne
e = e~x~ + e~y~
M = M~x~ * M~y~
W razie potrzeby dokonaj renormalizacji:
   Znajdź pierwszy niezerowy bit od lewej
   Dosuń go do pozycji 53
   Odejmij od wykładnika tyle, o ile pozycji przesunięto mantysę
Spakuj i zwróć liczbę
----

.Szczegół implementacyjny
[NOTE]
======================================================================
Opisany poniżej algorytm dotyczy dodawania dwóch liczb tego samego znaku.
Podobnie opisany dalej algorytm odejmowania odnosi się do liczb tego
samego znaku. Dodawanie/odejmowanie liczb w ogólności sprowadza się do 
jednego z dwóch przypadków: dodawania bądź odejmowania liczb o tym samym 
znaku. Funkcje realizujące ogólne przypadki tych operacji rozpoznają 
przypadek, z jakim mają do czynienia i przekazują sterowanie do funkcji 
odpowiadających rozpatrywanemu przypadkowi.
=======================================================================

.Dodawanie

Dodawanie liczb zmiennoprzecinkowych przedstawia większą trudność niż mnożenie, z uwagi na fakt, 
iż aby móc dodać mantysy, konieczne jest przekształcenie liczb tak, aby uzyskać ich reprezentacje
z identycznym wykładnikiem. Komplikuje to nieco implementację, wprowadza bowiem dodatkowy
krok obliczeń. Z uwagi na utratę dokładności przy podejściu polegającym na przesunieciu
w prawo mantysy mniejszego wykładnika bez zachowywania bitów przesuniętych poza prawą krawędź
liczby konieczne okazało się zastosowanie i tu operacji na liczbach 128-bitowych. W naszej 
realizacji mantysy początkowo zajmują górne 8 bajtów tych liczb. Następnie mantysy i wykładniki
są modyfikowane w taki sposób, aby uzyskać reprezentację z większym z dwóch wykładników argumentów.
Po tym kroku wystarczy dodać mantysy, zrenormalizować wynik, spakować go do reprezentacji binarnej
i zwrócić.

.Dodawanie (pseudokod)
----
Rozpakuj wartości do struktur
Sprawdź przypadki specjalne
M128~x~ = [m~x~, 0]
M128~y~ = [m~y~, 0]
d = e~x~ - e~y~
If d < 0:
   Przesuń M128~x~ o (-d) w prawo
   e = e~y~
Else:
   Przesuń M128~y~ o d w prawo
   e = e~x~
M128 = M128~x~ + M128~y~
Zrenormalizuj wynik (jak w mnożeniu)
Spakuj i zwróć liczbę
----

.Odejmowanie

Odejmowanie liczb zmiennoprzecinkowych jest operacją przebiegającą bardzo analogicznie do 
dodawania, z tą drobną różnicą, iż odejmujemy zawsze mniejszą mantysę od większej, zmieniając
w razie potrzeby znak wyniku. Nie ma więc potrzeby powtarzać przeprowadzonej w poprzednim
podpunkcie analizy i dyskusji.

.Dzielenie

Dzielenie swoją naturą przypomina mnożenie, z całą jego konceptualną prostotą. Dla +x = (-1)^s~x~^ * 2^e~x~^ * M~x~+, 
+y = (-1)^s~y~^ * 2^e~y~^ * M~y~+ mamy

+x / y = (-1)^s~x~+s~y~^ * 2^e~x~-e~y~^ * M~x~ / M~y~+

Jedyną problematyczną kwestią jest wyliczenie ilorazu mantys. Są one 64-bitowe, jednakowoż nie 
satysfakcjonuje nas zwykłe dzielenie całkowite. Implementacja tego fragmentu dzielenia pozostawia
nieco do życzenia. Po pierwsze, zrealizowane jest przy pomocy prostego, powolnego algorytmu 
wyliczającego kolejne bity rezultatu. To niestety nie koniec problemów. Wszystkie pozostałe 
operacje działają z dokładnością do przedostatniego bitu mantysy (wynik różni się od wzorcowej 
implementacji co najwyżej na ostatnim bicie), natomiast w przypadku dzielenia około 5% wyników 
posiada nieznacznie większe błędy. Jest to spowodowane najprawdopodobniej niedokładnością 
odejmowania w jednym z kroków algorytmu dzielenia (całość działa na liczbach 64-bitowych, bez 
wykorzystania dodatkowej precyzji oferowanej przez 128 bitów). Jakkolwiek defekt ten wydaje się 
nie wpływać w widoczny sposób na operacje wyższej warstwy (nie zaobserwowaliśmy różnic w średniej 
dokładności między implementacją wykorzystującą sprzętowy zmienny przecinek, a tą wykorzystującą
naszą arytmetykę), to stanowi potencjalny problem. Z uwagi na mnogość innych kwestii wymagających 
uwagi, oraz brak widocznego wpływu na resztę funkcjonalności postanowiliśmy zaniechać dalszego
śledzenia przyczyn błędu i ewentualnej jego eliminacji.

Implementacja algorytmów ewaluacji funkcji
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Exponent
^^^^^^^^

Funkcja 'FPL_exponent_64'

Proces zaczynamy od stworzenia tablicy obliczonych wcześniej wartości exponenta dla 354 wartości w okolicach zera (równomiernie rozłożonych z krokiem 1/512). W oryginalnej pracy rozkład ten nie jest równomierny, wybrane liczby odbiegają od tych równomiernie rozłożonych wartości o pewien epsilon który pozwoli na uzyskanie odpowiedniej dokładności, nie znaleźliśmy jednak prostego sposobu wyznaczania go. Następnie, korzystając z własności funkcji, rozbijamy
exp(x) = 2^x/log2^ = 2^n^ * exp(y)
W obliczeniu exp(y) wykorzystujemy wartości wyliczone wcześniej z tabeli oraz przybliżenie w sensie minimaxu exponenta na niewielkim przedziale służące za correction term. Szczegóły w załączonej pracy.

Poniżej przedstawiono wyniki działania funkcji z argumentami w przedziale (-20,20) z losową próbką 100000 punktów, porównywane z wynikami funkcji z biblioteki standardowej. Im wylosowany argument znajduje się dalej od 0 tym mniej miejsc znaczących będzie poprawne (ze względu na specyfikę funkcji wykładniczej szybko powiększającej drobne błędy), ogólnie jednak dokładność jest zadowalająca. Liczba z lewej strony to rząd wielkości w którym wyniki są dokładne, liczba z prawej to ilość argumentów dla których działanie funkcji wykazało taką dokładność.
----
dokładnie: 5588
  -23: 2397
  -22: 5369
  -21: 6202
  -20: 6376
  -19: 7109
  -18: 5717
  -17: 6819
  -16: 7444
  -15: 5361
  -14: 2448
  -13: 3926
  -12: 3661
  -11: 7937
  -10: 2297
   -9: 4626
   -8: 6178
   -7: 5511
   -6: 4433
   -5: 601
----


Logarytm
^^^^^^^^

Udostępniamy dwie funkcje, 'FPL_logarithm_E_64' podającą wartość logarytmu z bazą e, oraz 'FPL_logarithm_64' przyjmującą jako argument również bazę, udostępnioną dla wygody użytkownika.

Na początku stworzyliśmy 3 tabele zgodnie z instrukcjami - X zawierającą znalezione potrzebne nam wartości w okolicach zera (w naszym przypadku rozłożone równomiernie, bez uwzględnienia epsilona), F będącą dokładnym logarytmem wartości z X, oraz G zawierającą odwrotności F.
Dalej wykorzystujemy własność ln(x) = ln(y) + n*ln(2), ln(y) zaś obliczamy z wykorzystaniem wartości z tabeli oraz wielomianu przybliżającego logarytm dla małych wartości. Szczegóły w załączonej pracy.

Poniżej tabela z wynikami dla 100000 liczb wylosowanych z przedziału (0,100). Format jak dla Exponenta. W tym przypadku gwarantujemy dokładność do 14 miejsc znaczących.
----
dokładnie: 11091
  -18: 11
  -17: 68
  -16: 429
  -15: 88398
  -14: 3
----

Sinus i Cosinus
^^^^^^^^^^^^^^^

Funkcje 'FPL_sin_64' oraz 'FPL_cos_64'

Aby obliczyć dobrze funkcje trygonometryczne bardzo ważną częścią jest redukcja argumentu do przedziału na którym działa algorytm. Jest to jednak w większości przypadków trudne. Jak mówi praca, by tego dokonać potrzebowalibyśmy liczby PI zapisanej na 137 bitach. To jednak wymagałoby znaczącej ingerencji na niskim poziomie (w gruncie rzeczy napisania wszystkich podstawowych operacji by uwzględniały ten szczególny przypadek). Dlatego postanowiliśmy zignorować tą część i spróbować dokonać redukcji na zwykłych 64 bitach licząc, że wyniki okażą się zadowalające

Tak jak w innych przypadkach przygotowujemy tabelki z wyliczonymi wartościami funkcji sin i cos dla odpowiednio dobranych wartości bliskich 0 (nie uwzględniamy korekcji przez epsilon).

Po uzyskaniu pi w przedziale (-pi/4,pi/4), oraz wywołaniu odpowiedniej funkcji zgodnie z własnościami trygonometrycznymi przechodzimy do algorytmu właściwego. Dla odpowiednio małych x wynik jest przybliżony przez wielomian. W pozostałych przypadkach korzystamy z własności trygonometrycznych:
sin(x) = sin(X~i~+z) = sin(X~i~)*cos(z)+cos(X~i~)*sin(z)
cos(x) = cos(X~i~+z) = cos(X~i~)*cos(z)-sin(X~i~)*sin(z)
Gdzie sin/cos(X~i~) to tabelaryczna wartość a sin(z) i cos(z) są przybliżone wielomianami. Szczegóły w załączonej pracy.

Tabela dokładności dla liczb w zakresie (-50,50):
----
Sinus
dokładnie: 4669
  -19: 2
  -18: 12
  -17: 77
  -16: 1205
  -15: 50182
  -14: 43853

Cosinus
dokładnie: 6260
  -16: 1111
  -15: 48115
  -14: 44469
  -13: 45
----

Tangens i Cotangens
^^^^^^^^^^^^^^^^^^^

Funkcje 'FPL_tan_64' oraz 'FPL_cotan_64'

Pierwszym krokiem jest redukcja, ta sama co dla Sinusa/Cosinusa. Tworzymy też tabelki dokładnie wyliczonych wartości zgodnie z instrukcjami (tradycyjnie nie uwzględniając przesunięcia punktów o epsilon). Dla odpowiednio małych wartości x wynik przybliżamy wielomianem, w przeciwnym wypadku stosujemy własność trygonometryczną
tan(x) = tan(X~i~+z) = (tan(X~i~)+tan(z))/(1-tan(X~i~)*tan(z))
gdzie tan(X~i~) bierzemy z tabel, tan(z) zaś przybliżamy wielomianem. Szczegóły w załączonej pracy.

Poniżej tabela dokładności dla liczb w zakresie (-50,50). Niedokładność dla niektórych liczb może być wyjaśniona zmierzaniem tangensa do nieskończoności w okolicach wielokrotności pi/2, w związku z czym wiele miejsc znaczących znajduje się przed przecinkiem. W ogólności wyniki są jednak akceptowalne i można się spodziewać, że błąd nie wystąpi wcześniej niż na 9 miejscu znaczącym.
----
Tangent
-2147483648: 1314
  -18: 13
  -17: 65
  -16: 490
  -15: 24601
  -14: 42179
  -13: 21588
  -12: 6583
  -11: 2143
  -10: 669
   -9: 242
   -8: 70
   -7: 30
   -6: 8
   -5: 2
   -4: 3

Cotangent
-2147483648: 1363
  -17: 4
  -16: 1347
  -15: 17756
  -14: 54153
  -13: 18437
  -12: 4730
  -11: 1470
  -10: 503
   -9: 163
   -8: 55
   -7: 14
   -6: 4
   -5: 1
----

FPL Shell
~~~~~~~~~

Cele
^^^^

Jednym z wyzwań już od początkowej fazy projektu było kontrolowanie poprawności implementacji. 
Jakolwiek funkcjonalność już działająca była łatwa do zweryfikowania przy pomocy masowych testów
na losowych wartościach (opisanych w dalszej części dokumentu), poszukiwanie błędów było nieco
uciążliwe z uwagi na konieczność każdorazowego pisania kawałka kodu z odpowiednimi wartościami
w celu obserwacji rezultatów. Z tego powodu pojawił się pomysł stworzenia miniaturowego interpretera,
umożliwiającego ewaluację dowolnych wyrażeń arytmetycznych przy użyciu opracowywanej arytmetyki
software'owej oraz osobno, przy użyciu sprzętowego zmiennego przecinka. Pozwalałoby to na szybkie
i wygodne sprawdzanie zachowania funkcji z projektu dla konkretnych, wybranych wartości wejścia.
Tak powstała wstępna koncepcja, uzupełniona następnie o wsparcie dla funkcji z wyższej warstwy,
oraz funkcje pomocnicze (np. +hex+, wypisująca reprezentację binarną liczby).

Architektura
^^^^^^^^^^^^

Interpreter FPL Shell to standardowy program typu REPL (**R**ead-**E**val-**P**rint **L**oop).
Zbudowany jest w sposób typowy dla tego rodzaju aplikacji - wejście przetwarzane jest przy użyciu
flexa/bisona, edycję linii komend realizuje biblioteka GNU Readline. AST jest przetwarzane przez
interpreter bezpośrednio, bez translacji na żaden kod pośredni. Rozwiązanie takie podyktowane jest
prostotą implementacji, przy jednoczesnym braku jakichkolwiek wymagań efektywnościowych.

Opis języka
^^^^^^^^^^^

Literały
++++++++
FPL Shell operuje na literałach następujących typów:

* *liczby całkowite* [+integer+], zapisywane jako zwyczajne liczby całkowite, np. +666+
* *sprzętowy zmienny przecinek* [+native float+], zapisywane jako liczby rzeczywiste poprzedzone 
znakiem dolara ($), np. +$23.422+
* *software'owy zmienny przecinek*, zapisywane jako liczby rzeczywiste, np. +23.422+

Liczby całkowite posiadają niejawne konwersje do obydwu formatów liczb zmiennoprzecinkowych
gdy są użyte w wyrażeniach arytmetycznych je zawierających. W przypadku użycia w wywołaniach
funkcji jest to zależne od implementacji konkretnych funkcji. Obecnie wszystkie konwertują
argument na typ, na którym domyślnie operują.

Zdania (statements)
+++++++++++++++++++

Wspierane konstrukcje:

* wyrażenia arytmetyczne, np. +23 * ($13.9 + (-7.))+
* wywołania funkcji, np. +exp($1.23)+
* przypisania, np. +a = 7.0+

Funkcje wbudowane
+++++++++++++++++
* *hex(x)* - jako argument przyjmuje software'ową liczbę zmiennoprzecinkową, wypisuje jej
reprezentację heksadecymalną 
* *poly_eval(x, c~n~,...,c~0~)* - pobiera software'owe liczby zmiennoprzecinkowe jako argumenty,
oblicza +p(x) = c~n~x^n^ `+` ... `+` c~0~+
* *fpl_exp* - software'owa implementacja funkcji wykładniczej
* *fpl_log* - software'owa implementacja funkcji logarytmicznej
* *fpl_sqrt* - software'owa implementacja pierwiastka kwadratowego
* *fpl_sin* - software'owa implementacja funkcji sinus
* *fpl_cos* - software'owa implementacja funkcji cosinus
* *fpl_tan* - software'owa implementacja funkcji tangent
* *fpl_cotan* - software'owa implementacja funkcji cotangens
* *fpl_atan* - software'owa implementacja funkcji arcus tangens
* Wrappery na funkcje z biblioteki standardowej C implementujące analogiczne operacje - *exp*,
 *log*, *sqrt*, *sin*, *cos*, *tan*



